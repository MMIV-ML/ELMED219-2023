{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccf176c1-aec3-4db0-9ea1-073cdf560d95",
   "metadata": {},
   "source": [
    "A.L. Lundervold, 19.01.23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c987d0f4-c7c9-4f61-9bfd-f755de44d150",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06fafe1-1b0b-4c53-9ce2-160cc7f8b3ac",
   "metadata": {},
   "source": [
    "A simple example of text generation using a GPT2 model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34566024-4551-4879-88f3-e704602273cc",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59b2fcb-b0ef-494c-82fb-fa5cb3a02369",
   "metadata": {},
   "source": [
    "We use the ðŸ¤— Transfomers library: https://huggingface.co/docs/transformers/index and the PubMedGPT model from Stanford CRFM: https://huggingface.co/stanford-crfm/pubmedgpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a27cc0b-730d-4447-a3f7-99f2fc4d249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0608a1-4bd5-468f-87ae-626a8ffc2886",
   "metadata": {},
   "source": [
    "# Setup model and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc844ff-89ca-4f0e-b5b3-75a28bfe76c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"stanford-crfm/pubmedgpt\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"stanford-crfm/pubmedgpt\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543814b-2e7b-4f24-bcec-e014fa3192bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2afd7e-9572-48d8-8775-824061f8f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed295d-6e44-4a98-a316-4710a4a45e8c",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef7173-71f8-4614-af20-0f1a873573d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generator(\n",
    "\n",
    "    \"Photosynthesis is \", max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f9478-e48d-4a81-bcba-924d9d69309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c8a76-5f21-4cd4-b8bb-490912e0d5ec",
   "metadata": {},
   "source": [
    "# A simple application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edda4d8e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc05186-f44f-42f2-932d-fc1bb437557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prompt, length=150):\n",
    "    generated_text = generator(prompt, max_length=length)[0]['generated_text']\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3a55f-2f87-4932-8b0d-00654818639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a7071-aad9-4c1b-89c3-77d330f73d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    [\"Photosynthesis is \"],\n",
    "    [\"The resporitory system of \"],\n",
    "    [\"What distinguishes viruses from bacteria?\"]\n",
    "]\n",
    "\n",
    "description = \"Generate text using PubMedGPT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555f245",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f1ab0-1c8f-42ce-91d9-4fa39b9f3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(fn=predict, inputs=\"text\", outputs=\"text\", \n",
    "             description=description,\n",
    "             examples=examples).launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c8082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
